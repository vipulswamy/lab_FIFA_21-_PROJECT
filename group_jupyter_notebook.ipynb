{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e85cbdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3272772578.py, line 165)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [12]\u001b[1;36m\u001b[0m\n\u001b[1;33m    read_data(data)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Save Model Using Pickle\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#global declarations\n",
    "data = pd.read_csv('fifa21_train.csv')\n",
    "\n",
    "def read_data(data):    \n",
    "    display(data)\n",
    "    data.shape\n",
    "    \n",
    "def clean_missing_data():\n",
    "    #subset_1 = data[[\"Position\", \"Joined\",\"Volleys\",\"Curve\",\"Agility\",\"Balance\",\"Jumping\",\"Interceptions\",\"Positioning\",\"Vision\",\"Composure\",\"Sliding Tackle\",\"A/W\",\"D/W\" ]]\n",
    "    #data_2=data.dropna(axis=0)\n",
    "    data.dropna(axis=0)\n",
    "    # Reset index after drop\n",
    "    data.dropna().reset_index(drop=True)\n",
    "    # Drop row that has all NaN values\n",
    "    data.dropna(how='all')\n",
    "    #  check duplicates,frequencies or irrelevant observations\n",
    "    display(data['A/W'].unique())\n",
    "    display(data['A/W'].isna()==False)\n",
    "    display(data['A/W'].value_counts())\n",
    "    display(data['D/W'].unique())\n",
    "    display(data['D/W'].isna()==False)\n",
    "    display(data['D/W'].value_counts())\n",
    "    #My Action: i replace all the Nan values with low since I have no idea what these terminologies stand for\n",
    "    data[\"A/W\"].replace({np.nan: \"Low\"}, inplace=True)\n",
    "    data[\"D/W\"].replace({np.nan: \"Low\"}, inplace=True)\n",
    "    #cleaned subset\n",
    "    #subset_3 = data_2[[\"Position\", \"Joined\",\"Volleys\",\"Curve\",\"Agility\",\"Balance\",\"Jumping\",\"Interceptions\",\"Positioning\",\"Vision\",\"Composure\",\"Sliding Tackle\",\"A/W\",\"D/W\" ]]\n",
    "    #display(subset_3)\n",
    "    #data = data_2\n",
    "    # now i will iterate Manually.. coz i dont know how to use a loop here ..\n",
    "    # I am now cleaning the Volleys, Curve,Agility,Balance,Jumping\n",
    "    #trying to replace NaNs\n",
    "    # by the way the following also helps but i wont do it ;)\n",
    "    # df.groupby(['No', 'Name'], dropna=False, as_index=False).size()\n",
    "\n",
    "    #subset_4 = data[[\"Volleys\",\"Curve\",\"Agility\",\"Balance\",\"Jumping\"]]\n",
    "    #display(subset_4)\n",
    "    # since this is a continous variable it is safe to use the following code\n",
    "    #display(data['Volleys'].unique())\n",
    "    #display(data['Volleys'].isna()==False)\n",
    "    #display(data['Volleys'].value_counts())\n",
    "    # since this is a continous variable it is safe to use the following code\n",
    "    display(data['Volleys'].isnull().sum())\n",
    "    #output: I have 41 occurances of this, so i approximate them to 0.0\n",
    "    data[\"Volleys\"].replace({np.nan: 0.0}, inplace=True)\n",
    "    display(data['Volleys'].isnull().sum())\n",
    "    \n",
    "    # Clean Position\n",
    "    display(data['Position'].isnull().sum())\n",
    "    \n",
    "    # Check again for all the coloumns with missing data\n",
    "    nans_indices = data.columns[data.isna().any()].tolist()\n",
    "    nans_indices\n",
    "\n",
    "\n",
    "    #CLEANING SOME MORE\n",
    "    \n",
    "    # Clean Curve\n",
    "    display(data['Curve'].unique())\n",
    "    display(data['Curve'].isnull().sum())\n",
    "    #output: I have 41 occurances of this, so i approximate them to 0.0\n",
    "    data['Curve'].replace({np.nan: 0.0}, inplace=True)\n",
    "    display(data['Curve'].isnull().sum())\n",
    "\n",
    "    # Clean Agility\n",
    "    display(data['Agility'].unique())\n",
    "    display(data['Agility'].isnull().sum())\n",
    "    #output: I have 41 occurances of this, so i approximate them to 0.0\n",
    "    data['Agility'].replace({np.nan: 0.0}, inplace=True)\n",
    "    display(data['Agility'].isnull().sum())\n",
    "\n",
    "    # Clean Balance\n",
    "    display(data['Balance'].unique())\n",
    "    display(data['Balance'].isnull().sum())\n",
    "    #output: I have 41 occurances of this, so i approximate them to 0.0\n",
    "    data['Balance'].replace({np.nan: 0.0}, inplace=True)\n",
    "    display(data['Balance'].isnull().sum())\n",
    "\n",
    "    # Clean Jumping\n",
    "    display(data['Jumping'].unique())\n",
    "    display(data['Jumping'].isnull().sum())\n",
    "    #output: I have 41 occurances of this, so i approximate them to 0.0\n",
    "    data['Jumping'].replace({np.nan: 0.0}, inplace=True)\n",
    "    display(data['Jumping'].isnull().sum())\n",
    "    # Clean Position\n",
    "    display(data['Position'].isnull().sum())\n",
    "    data\n",
    "    \n",
    "    #CHeck and clean for the special symbols, other datatypes etc...\n",
    "    \n",
    "def preprocess():\n",
    "    #print('original data and its length are as folows:')\n",
    "    cols = data.columns\n",
    "    cols\n",
    "    #print('numeric data and its length are as folows:')\n",
    "    numerical_data = data._get_numeric_data().columns\n",
    "    catergorical_data = list(set(cols) - set(numerical_data))\n",
    "    \n",
    "       \n",
    "    #rafael's solution\n",
    "    df_num = data.select_dtypes(include=np.number)\n",
    "    #df_cat =df.select_dtypes(include=object)\n",
    "    df_num_columns = df_num.columns.tolist()\n",
    "    print('NUmerical variables list')\n",
    "    display(df_num_columns)\n",
    "    #df_cat_columns = list(df_cat.columns)\n",
    "    print('we have sorted numeric and categoric data')\n",
    "    #Clara's adivice\n",
    "    #column_datatypes = fifa.dtypes\n",
    "    #column_datatypes\n",
    "    #float64_columns = column_datatypes[column_datatypes == 'float64']\n",
    "    #float64_columns\n",
    "    #float64_columns.index.to_list() #this is to list all the elements that are categorical\n",
    "    #categorical_columns = column_datatypes[column_datatypes != 'float64']\n",
    "    #categorical_columns.index.to_list() #this is to list all the elements that are numerical\n",
    "    \n",
    "def clean_dataframe():\n",
    "    #save the original file\n",
    "    display(data)\n",
    "    data.to_pickle(\"data_cleaned.csv\")\n",
    "    return data    \n",
    "  \n",
    "    \n",
    "def correlation():\n",
    "    df = pd.DataFrame(data,columns=['ID','Age','OVA'])\n",
    "    corrMatrix = df.corr()\n",
    "    display(corrMatrix)    \n",
    "    sn.heatmap(corrMatrix, annot=True)\n",
    "    plt.show()    \n",
    "\n",
    "def model_output():\n",
    "    #column_names = data.columns\n",
    "    #array = data.values\n",
    "    #X = array[:,0:8]\n",
    "    #Y = array[:,8]\n",
    "    #test_size = 0.33\n",
    "    #seed = 7\n",
    "    #X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "    \n",
    "    # Fit the model on training set\n",
    "    #model = LinearRegression()\n",
    "    #model.fit(X_train, Y_train)\n",
    "\n",
    "    # save the model to disk\n",
    "    #filename = 'finalized_model.sav'\n",
    "    #pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "    # some time later...\n",
    "\n",
    "    # load the model from disk\n",
    "    #loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    #result = loaded_model.score(X_test, Y_test)\n",
    "    #print(result)\n",
    "\n",
    "\n",
    "read_data(data)\n",
    "preprocess()\n",
    "clean_missing_data()\n",
    "clean_dataframe()\n",
    "correlation()\n",
    "model_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad0f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbea237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
